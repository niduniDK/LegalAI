{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12789698,"sourceType":"datasetVersion","datasetId":8086167},{"sourceId":12790028,"sourceType":"datasetVersion","datasetId":8086397},{"sourceId":12946202,"sourceType":"datasetVersion","datasetId":8192684},{"sourceId":12946256,"sourceType":"datasetVersion","datasetId":8192718},{"sourceId":12946269,"sourceType":"datasetVersion","datasetId":8192725}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-20T03:57:52.541842Z","iopub.execute_input":"2025-08-20T03:57:52.542052Z","iopub.status.idle":"2025-08-20T03:57:52.887358Z","shell.execute_reply.started":"2025-08-20T03:57:52.542033Z","shell.execute_reply":"2025-08-20T03:57:52.886470Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/bills-data/bills.tsv\n/kaggle/input/gazettes-data/gazettes.tsv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Installing Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install faiss-cpu rank-bm25 google-generativeai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T05:47:57.286774Z","iopub.execute_input":"2025-09-07T05:47:57.286931Z","iopub.status.idle":"2025-09-07T05:48:03.723098Z","shell.execute_reply.started":"2025-09-07T05:47:57.286916Z","shell.execute_reply":"2025-09-07T05:48:03.722193Z"}},"outputs":[{"name":"stdout","text":"Collecting faiss-cpu\n  Downloading faiss_cpu-1.12.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\nCollecting rank-bm25\n  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\nRequirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (1.34.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.173.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.40.3)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (3.20.3)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\nRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.4)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\nRequirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.49.0rc1)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core->google-generativeai) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nDownloading faiss_cpu-1.12.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\nInstalling collected packages: rank-bm25, faiss-cpu\nSuccessfully installed faiss-cpu-1.12.0 rank-bm25-0.2.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# **Preprocessing Text Data**\n\nUsed [previous](https://github.com/niduniDK/LegalAI/blob/main/Notebooks/dp-1-preprocess%20bills.ipynb) methods for data cleaning.","metadata":{}},{"cell_type":"code","source":"import re\nimport unicodedata\nfrom typing import Optional\n\ndef normalize_unicode(text: str) -> str:\n    \"\"\"Normalize unicode characters to their closest ASCII representation.\"\"\"\n    try:\n        return unicodedata.normalize('NFKC', text).encode('ASCII', 'ignore').decode('ASCII')\n    except Exception:\n        return text\n\ndef normalize_whitespace(text: str) -> str:\n    \"\"\"Normalize whitespace, preserving essential structure.\"\"\"\n    try:\n        # Replace multiple spaces with a single space\n        text = re.sub(r'[ \\t]+', ' ', text)\n        # Normalize newlines (keep single newlines, remove excessive ones)\n        text = re.sub(r'\\n{2,}', '\\n', text)\n        return text.strip()\n    except re.error:\n        return text.strip()\n\nimport re\n\ndef clean_legal_metadata(text: str) -> str:\n    \"\"\"\n    Remove repetitive headers, footers, and metadata from Sri Lankan legal bills.\n    \"\"\"\n    try:\n        patterns = [\n            # Gazette headers\n            r'^THE GAZETTE OF THE DEMOCRATIC SOCIALIST REPUBLIC OF SRI LANKA\\s*Part\\s+[IVX]+\\s*of\\s+[A-Za-z]+\\s+\\d+,\\s+\\d+\\s*SUPPLEMENT\\s*$',\n            r'^\\(Issued\\s+on\\s+\\d+\\.\\s*\\d+\\.\\s*\\d+\\)\\s*$',\n            # Printing and purchase information\n            r'^PRINTED AT THE DEPARTMENT OF GOVERNMENT PRINTING.*?$',\n            r'^TO BE PURCHASED AT THE GOVERNMENT PUBLICATIONS BUREAU.*?$',\n            r'^Price\\s*:\\s*Rs\\.\\s*\\d+\\.\\d+\\s*Postage\\s*:\\s*Rs\\.\\s*\\d+\\.\\d+\\s*$',\n            # Bill identifiers\n            r'^\\d+\\s*-PL\\s+\\d+-\\d+\\s*\\(\\d+/\\d+\\)\\s*$',\n            # Subscription details\n            r'^Annual subscription of English Bills and Acts of the Parliament.*?$',\n            r'^Payable to the SUPERINTENDENT, GOVERNMENT PUBLICATIONS BUREAU.*?$',\n            # Other repetitive metadata\n            r'^N\\.B\\.- Part [A-Z0-9]+\\s*of the Gazette No\\.\\s*\\d+[,\\d]*\\s*of\\s*\\d{2}\\.\\d{2}\\.\\d{4}\\s*was not published\\.\\s*$',\n            r'^Published by Authority\\s*$',\n        ]\n        \n        # Apply all patterns\n        for pattern in patterns:\n            text = re.sub(pattern, '', text, flags=re.IGNORECASE | re.DOTALL)\n        \n        # Remove extra newlines and leading/trailing whitespace\n        text = '\\n'.join(line.strip() for line in text.split('\\n') if line.strip())\n        \n        return text\n    except re.error:\n        # fallback: minimal cleanup\n        return text.strip()\n\n\n\ndef remove_special_characters(text: str) -> str:\n    \"\"\"Remove special characters, preserving essential punctuation for legal text.\"\"\"\n    try:\n        # Preserve alphanumeric, spaces, and common legal punctuation (.,;:-/()&)\n        text = re.sub(r'[^\\w\\s.,;:\\-/()&]', '', text)\n        return text\n    except re.error:\n        return text\n\ndef preprocess_legal_document(text: str) -> Optional[str]:\n    \"\"\"Main function to preprocess legal document text while preserving core content and unique details.\"\"\"\n    # if not text or not text.strip():\n    #     return None\n\n    try:\n        # Step 1: Normalize unicode\n        text = normalize_unicode(text)\n\n        # Step 2: Clean specific metadata\n        text = clean_legal_metadata(text)\n\n        # Step 3: Remove special characters\n        text = remove_special_characters(text)\n\n        # Step 4: Normalize whitespace\n        text = normalize_whitespace(text)\n\n        return text.strip()\n    except Exception:\n        # Fallback to minimal cleaning\n        return normalize_whitespace(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T05:48:26.839338Z","iopub.execute_input":"2025-09-07T05:48:26.840179Z","iopub.status.idle":"2025-09-07T05:48:26.849452Z","shell.execute_reply.started":"2025-09-07T05:48:26.840132Z","shell.execute_reply":"2025-09-07T05:48:26.848914Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Loading and Cleaning Bills","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nbills = pd.read_csv(\"/kaggle/input/bills-data/bills.tsv\", sep=\"\\t\")\nbills.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T05:49:02.609247Z","iopub.execute_input":"2025-09-07T05:49:02.610014Z","iopub.status.idle":"2025-09-07T05:49:03.494104Z","shell.execute_reply.started":"2025-09-07T05:49:02.609988Z","shell.execute_reply":"2025-09-07T05:49:03.493372Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                filename                                            content\n0  2010-10-16-2010_E.txt  THE GAZETTE OF THE DEMOCRATIC SOCIALIST REPUBL...\n1  2010-10-17-2010_E.txt  PARLIAMENT OF THE DEMOCRATIC SOCIALIST REPUBLI...\n2  2010-10-18-2010_E.txt  PARLIAMENT OF THE DEMOCRATIC SOCIALIST REPUBLI...\n3   2010-5-01-2010_E.txt  THE GAZETTE OF THE DEMOCRATIC SOCIALIST REPUBL...\n4   2010-5-02-2010_E.txt  THE GAZETTE OF THE DEMOCRATIC SOCIALIST REPUBL...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2010-10-16-2010_E.txt</td>\n      <td>THE GAZETTE OF THE DEMOCRATIC SOCIALIST REPUBL...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010-10-17-2010_E.txt</td>\n      <td>PARLIAMENT OF THE DEMOCRATIC SOCIALIST REPUBLI...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010-10-18-2010_E.txt</td>\n      <td>PARLIAMENT OF THE DEMOCRATIC SOCIALIST REPUBLI...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2010-5-01-2010_E.txt</td>\n      <td>THE GAZETTE OF THE DEMOCRATIC SOCIALIST REPUBL...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2010-5-02-2010_E.txt</td>\n      <td>THE GAZETTE OF THE DEMOCRATIC SOCIALIST REPUBL...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"bills[\"content\"] = bills[\"content\"].map(preprocess_legal_document)\nbills.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T05:49:07.847010Z","iopub.execute_input":"2025-09-07T05:49:07.847289Z","iopub.status.idle":"2025-09-07T05:49:10.283881Z","shell.execute_reply.started":"2025-09-07T05:49:07.847268Z","shell.execute_reply":"2025-09-07T05:49:10.283118Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                filename                                            content\n0  2010-10-16-2010_E.txt  THE GAZETTE OF THE DEMOCRATIC SOCIALIST REPUBL...\n1  2010-10-17-2010_E.txt  PARLIAMENT OF THE DEMOCRATIC SOCIALIST REPUBLI...\n2  2010-10-18-2010_E.txt  PARLIAMENT OF THE DEMOCRATIC SOCIALIST REPUBLI...\n3   2010-5-01-2010_E.txt  THE GAZETTE OF THE DEMOCRATIC SOCIALIST REPUBL...\n4   2010-5-02-2010_E.txt  THE GAZETTE OF THE DEMOCRATIC SOCIALIST REPUBL...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2010-10-16-2010_E.txt</td>\n      <td>THE GAZETTE OF THE DEMOCRATIC SOCIALIST REPUBL...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010-10-17-2010_E.txt</td>\n      <td>PARLIAMENT OF THE DEMOCRATIC SOCIALIST REPUBLI...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010-10-18-2010_E.txt</td>\n      <td>PARLIAMENT OF THE DEMOCRATIC SOCIALIST REPUBLI...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2010-5-01-2010_E.txt</td>\n      <td>THE GAZETTE OF THE DEMOCRATIC SOCIALIST REPUBL...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2010-5-02-2010_E.txt</td>\n      <td>THE GAZETTE OF THE DEMOCRATIC SOCIALIST REPUBL...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nuser_secret = UserSecretsClient()\n\nGEMINI_API_KEY = user_secret.get_secret(\"gemini-api-key\")\nGROQ_API_KEY = user_secret.get_secret(\"groq_api_key\")\nGROQ_MODEL = 'llama3-70b-8192'\n\ndef query_qroq(prompt: str) -> str:\n    response = requests.post(\n        'https://api.groq.com/openai/v1/chat/completions',\n        headers = {\n            'Authorization': f\"Bearer {GROQ_API_KEY}\",\n            'Content-type': 'application/json'\n        },\n        json={\n            'model': GROQ_MODEL,\n            'messages': [{'role': 'user', 'content': prompt}],\n            'temperature':0.0\n        }\n    )\n\n    if response.ok:\n        data = response.json()\n        return data['choices'][0]['message']['content']\n    else:\n        print(f\"Error: {response.status_code} - {response.text}\")\n        return \"Error in API request\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T05:50:55.079733Z","iopub.execute_input":"2025-09-07T05:50:55.080417Z","iopub.status.idle":"2025-09-07T05:50:55.356202Z","shell.execute_reply.started":"2025-09-07T05:50:55.080386Z","shell.execute_reply":"2025-09-07T05:50:55.355646Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# **Chunking**\n\nSource: [15 Chunking Techniques.](https://www.analyticsvidhya.com/blog/2024/10/chunking-techniques-to-build-exceptional-rag-systems/)","metadata":{}},{"cell_type":"code","source":"def chunk_df(df, method):\n    chunks = []\n    for _, row in df.iterrows():\n        chunk_list = df[\"content\"].map(method)\n        for i in range(0, len(chunk_list)):\n            chunks.append({\n                \"name\": df[\"filename\"],\n                \"chunk_id\": i,\n                \"content\": chunk_list[i]\n            })\n\n    return pd.DataFrame(chunks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T05:51:00.921587Z","iopub.execute_input":"2025-09-07T05:51:00.921866Z","iopub.status.idle":"2025-09-07T05:51:00.926593Z","shell.execute_reply.started":"2025-09-07T05:51:00.921846Z","shell.execute_reply":"2025-09-07T05:51:00.925658Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# *Sentence-based Chunking*","metadata":{}},{"cell_type":"code","source":"import spacy\n\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef sentence_chunk(text):\n    doc = nlp(text)\n    return [sent.text for sent in doc.sents]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T06:31:07.739944Z","iopub.execute_input":"2025-08-20T06:31:07.740260Z","iopub.status.idle":"2025-08-20T06:31:07.744503Z","shell.execute_reply.started":"2025-08-20T06:31:07.740238Z","shell.execute_reply":"2025-08-20T06:31:07.743763Z"}},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":"# *Paragraph-wise Chunking*","metadata":{}},{"cell_type":"code","source":"def paragraph_chunk(text):\n    paragraphs = text.split('\\n\\n')\n    return paragraphs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T05:51:05.719571Z","iopub.execute_input":"2025-09-07T05:51:05.719940Z","iopub.status.idle":"2025-09-07T05:51:05.724069Z","shell.execute_reply.started":"2025-09-07T05:51:05.719909Z","shell.execute_reply":"2025-09-07T05:51:05.723210Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# *Sliding Window Chunking*","metadata":{}},{"cell_type":"code","source":"def sliding_window_chunk(text, chunk_size=100, overlap=20):\n    tokens = text.split()\n    chunks = []\n    for i in range(0, len(tokens), chunk_size - overlap):\n        chunk = ' '.join(tokens[i:i + chunk_size])\n        chunks.append(chunk)\n    return chunks\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# *Hierarchical Chunking*","metadata":{}},{"cell_type":"code","source":"def get_section_keywords(text):\n    \n    prompt = f\"\"\"\n    You are an intelligent agent. Identify the section keywords in the given text.\n\n    Example: \n        text: \"\n            \"THE GAZETTE OF THE DEMOCRATIC SOCIALIST REPUBLIC OF SRI LANKA Part II of October 01, 2010 SUPPLEMENT (Issued on 04.10.2010) LOCAL AUTHORITIES (SPECIAL PROVISIONS) BILL to amend the Municipal Councils Ordinance, the Urban Councils Ordinance and the Pradeshiya Sabhas Act, No. 15 of 1987 Ordered to be published by the Minister of Local Government and Provincial Councils PRINTED AT THE DEPARTMENT OF GOVERNMENT PRINTING, SRI LANKA TO BE PURCHASED AT THE GOVERNMENT PUBLICATIONS BUREAU, COLOMBO 5 Price : Rs. 8.00 Postage : Rs. 5.00\n    \n        Local Authorities (Special Provisions) Short title. L.D.-O. 19/2008 AN ACT TO AMEND THE MUNICIPAL COUNCILS ORDINANCE, THE URBAN COUNCILS ORDINANCE AND THE PRADESHIYA SHABHAS ACT, NO. 15 OF 1987. BE it enacted by the Parliament of the Democratic Socialist Republic of Sri Lanka as follows:- This Act may be cited as the Local Authorities (Special Provisions) Act, No. of 2010. PART I AMENDMENTS TO THE MUNICIPAL COUNCILS ORDINANCE (CHAPTER 252) Section 5 of the Minicipal Councils Ordinance (CHAPTER 252) (hereinafter in this Part referred to as the “principal enactment”) is hereby repealed and the following section is substituted therefor :- (1) Each Municipal Council shall consist of :- (a) such number of elected Councillors as determined by the Minister by Order made under section 3c of the Local Authorities Elections Ordinance (Cap. 262); and (b) such number of other Councillors not exceeding thirty per centum of the total number of elected Councillors as determined by the Minister by Order Replacement of section 5 of Chapter 252. “Composition of Municipal Councils.\n        \n        Local Authorities (Special Provisions) made under section 3C of the Local Authorities Elections Ordinance (Cap. 262), to be returned as Councillors under section 65A of that Ordinance, to represent those electors who have not secured any representation in the Council, at the election held for the election of Councillors.”; and (2) Where the number constituting thirty per centum referred to in paragraph (b) of subsection (1) is an integer and fraction, the integer shall be deemed to be the number which shall constitute such thirty per centum, for the purpose of that subsection.”. Section 13 of the principal enactment is hereby amended in subsection (3) of that section, by the substitution for all the words from “with the provisions of the Local Authorities Elections Ordinance,” to the end of that subsection, and the substitution therefore of the words “with the provisions of section 66A of the Local Authorities Elections Ordinance (Cap. 262), and the person so elected shall hold office as a Councillor, until the next succeeding general election of Councillors of that Council.”. Section 14 of the principal enactment as amended by Law No. 24 of 1977, is hereby further amended as follows:- (1) by the repeal of paragraph (b) of subsection (2) of that section, and the substitution therefor of the following paragraph- “(b) a Mayor or Deputy Mayor who resigns or vacates his office, shall however continue to be a Councillor.”; and Amendment of section 13 of the principal enactment. Amendment of section 14 of the principal enactment.\n        \n        Local Authorities (Special Provisions) (2) by the repeal of subsection (7) of that section and the substitution therefor of the following subsection:- “(7) Whenever the office of Mayor of a Municipal Council falls vacant, notice of such vacancy shall forthwith be given by the Commissioner to the Commissioner of Local Government and the Commissioner of Local Government shall thereupon proceed to fill such vacancy in the manner provided for the same in the Local Authorities Elections Ordinance (Cap. 262).”. Section 215A of the principal enactment is hereby amended as follows:- (1) by the substitution for all the words beginning from the words “Where a budget or supplementary budget” to the end of that section, of the following words- “Where a budget is not passed by the Council within two weeks after it is resubmitted before such Council, the Mayor shall be deemed, at the expiry of such two weeks period, to have resigned from the office of Mayor.”; and (2) by the substitution for the marginal note to that section of the following marginal note:- “ Effect of not passing the budget by the Council.”. Amendment of section 215A of the principal enactment.\n        \n        Local Authorities (Special Provisions) PART II AMENDMENTS TO THE URBAN COUNCILS ORDINANCE (CHAPTER 255) Section 5 of the Urban Councils Ordinance (Chapter 255) (hereinafter in this Part referred to as the “principal enactment”) is hereby repealed and the following section is substituted therefore:- (1) Each Urban Council shall consist of :- (a) such number of elected Councillors as determined by the Minister by Order made under section 3C of the Local Authorities Elections Ordinance (Cap. 262) ; and (b) such number of other Councillors not exceeding thirty per centum of the total number of elected Councillors as determined by the Minister by Order made under section 3C of the Local Authorities Elections Ordinance (Cap. 262), to be returned as Councillors under section 65A of that Ordinance, to represent those electors who have not secured any representation in the Council, at the election held for the election of Councillors.”; and (2) Where the number constituting thirty per centum referred to in paragraph (b) of subsection (1) is an integer and fraction, the integer shall be deemed to be the number which shall constitute such thirty per centum, for the purpose of that subsection.”. “Composition of Municipal Councils. Replacement of section 5 of Chapter 255.\n        \n        Local Authorities (Special Provisions) Section 12 of the principal enactment is hereby amended in subsection (3) of that section, by the substitution for the words “the provisions of written law for the time being applicable in that behalf,” of the words “the provisions of section 66A of the Loacl Authorities Elections Ordinance (Cap. 262)”. Section 19 of the principal enactment as amended by Law No. 24 of 1977, is hereby further amended as follows:- (1) in subsection (1) of that section, by the substitution for the words “in accordance with the provisions of written law for the time being applicable in that behalf.”, of the words “in accordance with the provisions of the Local Authorities Elections Ordinance (Cap. 262).”; (2) in subsection (2) of that section, by the substitution for all the words from the words “vacates such office.”, to the end of that subsection, of the words “vacates such office. A Chairman or Vice-Chairman who resigns or vacates his office shall however continue to be a member of the Council.”; and (3) by the repeal of subsection (7) of that section and the substitution therefore of the following subsection :- “(7) Whenever the office of Chairman of an Urban Council falls vacant, notice of such vacancy shall forthwith be given by the Secretary of the Council to the Commissioner of Local Government and the Commissioner of Local Government shall thereupon proceed to fill such vacancy in the manner provided for the same in the Local Authorities Elections Ordinance (Cap 262).”. Amendment of section 12 of the principal enactment. Amendment of section 19 of the principal enactment.\n        \n        Local Authorities (Special Provisions) Section 178A of the principal enactment as amended by Law No. 24 of 1977, is hereby further amended as follows:- (1) by the substitution for all the words beginning from the words “Where a budget or supplementary budget,” to the end of that section, of the following words :- “Where a budget is not passed by the Council within two weeks after it is re-submitted before such Council, the Chairman shall be deemed, at the expiry of such two weeks period, to have resigned from the office of Chairman.”; and (2) by the substitution for the marginal note to that section of the following marginal note:- “ Effect of not passing the budget by the Council.”. 10. Section 184 of the principal enactment as amended by Law No. 24 of 1977, is hereby further amended in subsection (3) of that section, by the substitution for the words “and the provisions of written law for the time being applicable in that behalf “, of the words “and the provisions of the Local Authorities Elections Ordinance (Cap. 262)”. 11. Section 249 of the principal enactment as amended by Law No. 24 of 1977, is hereby further amended in the definition of the expression “Chairman and Vice Chairman”, by the substitution for the words “the provisions of written law for the time being applicable in that behalf;”, of the words “the provisions of the Local Authorities Elections Ordinance (Cap. 262);”. Amendment of section 249 of the principal enactment. Amendment of section 184 of the principal enactment. Amendment of section 178A of the principal enactment.\n        \n        Local Authorities (Special Provisions) PART III AMENDMENTS TO THE PRADESHIYA SABHA ACT 12. Section 4 of the Pradeshiya Sabha Act, No. 15 of 1987 (hereinafter in this Part referred to as the “principal enactment”) is hereby repealed and the following section is subtituted therefore:- 4. (1) A Pradeshiya Sabha constituted by an Order under subsection (1) of section 2, shall consist of:- (a) such number of elected members as determined by the Minister by Order made under section 3C of the Local Authorities Elections Ordinance ( Cap. 262); and (b) such number of other members not exceeding thirty per centum of the total number of elected members as determined under paragraph (a), to be returned as members under the Local Authorities Elections Ordinance (Cap. 262), to represent those electors who have not secured any representation in the Sabha, at an election held for the election of members . (2) Where the number constituting thirty per centum referred to in paragraph (b) of subsection (1) is an integer and fraction, the integer shall be deemed to be the number which shall constitute such thirty per centum, for the purpose of that subsection.”. “Composition of Pradeshiya Sabhas. Amendment of section 4 of Act No. 15 of 1987.\n        \n        Local Authorities (Special Provisions) 13. Section 169 of the principal enactment is hereby amended as follows:- (1) by the substitution for all the words beginning from the words “Where a budget or supplem entary budget,” to the end of that section, of the following words :- “Where a budget is not passed by the Pradeshiya Sabha within two weeks after it is resubmitted before such Pradeshiya Sabha, the Chairman shall be deemed, at the expiry of such two weeks period, to have resigned from the office of Chairman.”; and (2) by the substitution for the marginal note to that section of the following marginal note:- “Effect of not passing the budget by the Pradeshiya Sabha.”. 14. In the event of any inconsistency between the Sinhala and Tamil texts of this Act, the Sinhala text shall prevail. Amendment of section 169 of the principal enactment. Sinhala text to prevail in case of inconsistency.\n        \n        Local Authorities (Special Provisions) Annual subscription of English Bills and Acts of the Parliament Rs. 885 (Local), Rs. 1,180 (Foreign), Payable to the SUPERINTENDENT, GOVERNMENT PUBLICATIONS BUREAU, DEPARTMENT OF GOVERNMENT INFORMATION, NO. 163, KIRULAPONA MAWATHA, POLHENGODA, COLOMBO 05 before 15th December each year in respect of the year following.\"\n        \n            \"\n        section_keywords: [\n            \"PART I\", \"PART II\", \"PART III\", \"Section \", \"Replacement of section\", \"Amendment of section\",\"LOCAL AUTHORITIES\", \"Short title\"\n        ]\n\n    Use the {text} as the text\n    \"\"\"\n\n    return query_groq(prompt)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def hierarchical_chunk(text):\n    sections = []\n    current_section = []\n    section_keywords = get_section_keywords(text)\n    for line in text.splitlines():\n        if any(keyword in line for keyword in section_keywords):\n            if current_section:\n                sections.append(\"\\n\".join(current_section))\n            current_section = [line]\n        else:\n            current_section.append(line)\n    if current_section:\n        sections.append(\"\\n\".join(current_section))\n    return sections\n\n# # Applying Hierarchical Chunking\n# section_keywords = [\"Introduction\", \"Overview\", \"Methods\", \"Conclusion\"]\n# hierarchical_chunks = hierarchical_chunk(sample_text, section_keywords)\n# for chunk in hierarchical_chunks:\n#     print(chunk, '\\n---\\n')\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# *Sliding Window + Paragraph*","metadata":{}},{"cell_type":"code","source":"def hybrid_chunk_sliding_para(text):\n    texts = paragraph_chunk(text)\n    chunks = []\n    for text in texts:\n        chunks.extend(sliding_window_chunk(text, chunk_size=100, overlap=20))\n    return chunks\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# *Sliding Window + Sentence*","metadata":{}},{"cell_type":"code","source":"def hybrid_chunk_sliding_sentence(text):\n    texts = sentence_chunk(text)\n    chunks = []\n    for text in texts:\n        chunks.extend(sliding_window_chunk(text, chunk_size=100, overlap=20))\n    return chunks","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Implementing RAG**","metadata":{}},{"cell_type":"code","source":"bills_para_chunks = chunk_df(bills, paragraph_chunk)\nbills_sentence_chunks = chunk_df(bills, sentence_chunk)\nbills_sliding_chunks = chunk_df(bills, sliding_window_chunk)\nbills_hierarchical_chunks = chunk_df(bills, hierarchical_chunk)\nbills_hybrid_sp_chunks = chunk_df(bills, hybrid_chunk_sliding_para)\nbills_hybrid_ss_chunks = chunk_df(bills, hybrid_chunk_sliding_sentence)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Retriever Module Implementation**","metadata":{}},{"cell_type":"code","source":"pip install sentence_transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T05:54:57.145828Z","iopub.execute_input":"2025-09-07T05:54:57.146108Z","iopub.status.idle":"2025-09-07T05:56:02.423472Z","shell.execute_reply.started":"2025-09-07T05:54:57.146088Z","shell.execute_reply":"2025-09-07T05:56:02.422569Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.52.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (1.15.3)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (0.33.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (11.2.1)\nRequirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence_transformers) (4.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.5.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.4)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.1.5)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence_transformers)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence_transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence_transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence_transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence_transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence_transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence_transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.6.15)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence_transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence_transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# from sentence_transformers import SentenceTransformers\nimport google.generativeai as genai\n\ngenai.configure(api_key=GEMINI_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T05:58:31.020056Z","iopub.execute_input":"2025-09-07T05:58:31.020676Z","iopub.status.idle":"2025-09-07T05:58:31.024201Z","shell.execute_reply.started":"2025-09-07T05:58:31.020653Z","shell.execute_reply":"2025-09-07T05:58:31.023457Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"# Vanila RAG Approach","metadata":{}},{"cell_type":"code","source":"class VanilaRAG:\n    def __init__(\n        self,\n        model=None,\n        gemini_api_key,\n        chunk_df\n    ):\n        index_path = f\"bills.faiss\"\n        data_path = f\"bills_data.pkl\"\n        bm25_path = f\"bills_bm25.pkl\"\n\n        # Load cached data if it exists and reload not requested\n        if (\n            not reload\n            and os.path.exists(index_path)\n            and os.path.exists(data_path)\n            and os.path.exists(bm25_path)\n        ):\n            self.index = faiss.read_index(index_path)\n            data = joblib.load(data_path)\n            self.documents = data['documents']\n            self.metadata = data['metadata']\n            self.bm25_corpus = joblib.load(bm25_path)\n            self.bm25 = BM25Okapi(self.bm25_corpus)\n            return\n\n        self.client = genai.GenerativeModel(\"gemini-2.0-flash\")\n\n        self.chunk_df = chunk_df\n        self.documents = chunk_df[\"content\"].to_list()\n\n        self.model = model\n        \n        if not model:\n            self.model = SentenceTransformer('nlpaueb/legal-bert-base-uncased')\n            \n\n        embeddings = self.model.encode(self.documents, batch_size=32, show_progress_bar=True)\n        self.index = faiss.IndexFlatL2(self.dimension)\n        self.index.add(np.array(embeddings, dtype=np.float32))\n\n        # Save FAISS index and data\n        faiss.write_index(self.index, index_path)\n        joblib.dump({'documents': self.documents, 'metadata': self.metadata}, data_path)\n\n        # Build and save BM25 index\n        self.build_bm25()\n        joblib.dump(self.bm25_corpus, bm25_path)\n\n    def build_bm25(self):\n        self.bm25_corpus = [re.findall(r\"\\w+\", doc.lower()) for doc in self.documents]\n        self.bm25 = BM25Okapi(self.bm25_corpus)\n\n    def retrieve(self, query: str, k: int = 5) -> List[Tuple[str, dict, float]]:\n        # FAISS embedding retrieval\n        query_embedding = self.model.encode([query])[0]\n        distances, indices = self.index.search(np.array([query_embedding], dtype=np.float32), k)\n        results = []\n\n        for idx, distance in zip(indices[0], distances[0]):\n                if idx < len(self.documents):\n                    score = 1 / (1 + distance)  # Convert L2 distance to similarity score\n                    results.append((self.documents[idx], self.metadata[idx], score))\n            return results\n\n    def bm25_retrieve(self, query: str, k: int = 5) -> List[Tuple[str, dict, float]]:\n        # BM25 keyword retrieval\n        tokens = re.findall(r\"\\w+\", query.lower())\n        scores = self.bm25.get_scores(tokens)\n        top_indices = np.argsort(scores)[::-1][:k]\n        results = []\n        for i in top_indices:\n            if scores[i] > 0:\n                results.append((self.documents[i], self.metadata[i], float(scores[i])))\n        return results\n\n    def generate_response(self, query: str, retrieved_docs: List[Tuple[str, dict, float]]) -> str:\n        context = \"\\n\\n\".join([f\"Document: {doc[0]}\\nMetadata: {doc[1]}\" for doc in retrieved_docs])\n        prompt = f\"\"\"You are a legal assistant powered by a RAG system. Use the following context to answer the query accurately and concisely. If the context doesn't provide enough information, say so.\n\n            Context:\n            {context}\n            \n            Query:\n            {query}\n            \n            Answer:\n            \"\"\"\n        # response = self.client.generate_content(\n        #     model=\"gpt-2.0-flash\",\n        #     messages=[\n        #         {\"role\": \"system\", \"content\": \"You are a helpful legal assistant.\"},\n        #         {\"role\": \"user\", \"content\": prompt}\n        #     ],\n        #     max_tokens=500,\n        #     temperature=0.7\n        # )\n        response = self.client.generate_content(prompt)\n        # return response.choices[0].message.content.strip()\n        return response.text","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# GraphRAG Approach","metadata":{}},{"cell_type":"code","source":"pip install langextract","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T05:51:31.370029Z","iopub.execute_input":"2025-09-07T05:51:31.370527Z","iopub.status.idle":"2025-09-07T05:51:35.222192Z","shell.execute_reply.started":"2025-09-07T05:51:31.370502Z","shell.execute_reply":"2025-09-07T05:51:35.221463Z"}},"outputs":[{"name":"stdout","text":"Collecting langextract\n  Downloading langextract-1.0.9-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langextract) (1.4.0)\nRequirement already satisfied: aiohttp>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from langextract) (3.12.13)\nCollecting async_timeout>=4.0.0 (from langextract)\n  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\nCollecting exceptiongroup>=1.1.0 (from langextract)\n  Downloading exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)\nRequirement already satisfied: google-genai>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from langextract) (1.21.1)\nRequirement already satisfied: ml-collections>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from langextract) (1.1.0)\nRequirement already satisfied: more-itertools>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from langextract) (10.7.0)\nRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from langextract) (1.26.4)\nRequirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from langextract) (2.2.3)\nRequirement already satisfied: pydantic>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langextract) (2.11.7)\nCollecting python-dotenv>=0.19.0 (from langextract)\n  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.11/dist-packages (from langextract) (6.0.2)\nRequirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.11/dist-packages (from langextract) (2.32.4)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from langextract) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from langextract) (4.14.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.0->langextract) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.0->langextract) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.0->langextract) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.0->langextract) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.0->langextract) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.0->langextract) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.0->langextract) (1.20.1)\nRequirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai>=0.1.0->langextract) (4.9.0)\nRequirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai>=0.1.0->langextract) (2.40.3)\nRequirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai>=0.1.0->langextract) (0.28.1)\nRequirement already satisfied: tenacity<9.0.0,>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from google-genai>=0.1.0->langextract) (8.5.0)\nRequirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai>=0.1.0->langextract) (15.0.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->langextract) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->langextract) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->langextract) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->langextract) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->langextract) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->langextract) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->langextract) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->langextract) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->langextract) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.8.0->langextract) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.8.0->langextract) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.8.0->langextract) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->langextract) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->langextract) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->langextract) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.0->langextract) (2025.6.15)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai>=0.1.0->langextract) (1.3.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai>=0.1.0->langextract) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai>=0.1.0->langextract) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai>=0.1.0->langextract) (4.9.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai>=0.1.0->langextract) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai>=0.1.0->langextract) (0.16.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->langextract) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20.0->langextract) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20.0->langextract) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20.0->langextract) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20.0->langextract) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20.0->langextract) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai>=0.1.0->langextract) (0.6.1)\nDownloading langextract-1.0.9-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.2/106.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\nDownloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\nDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\nInstalling collected packages: python-dotenv, exceptiongroup, async_timeout, langextract\nSuccessfully installed async_timeout-5.0.1 exceptiongroup-1.3.0 langextract-1.0.9 python-dotenv-1.1.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import networkx as nx\nfrom pprint import pprint\nimport textwrap\nimport langextract as lx\n\nneo4j_username = \"neo4j\"\nneo4j_id = \"7c554630\"\nneo4j_pwd = \"q7uKz7eeq-9P3aXoO-6GFuGwyTnU-k-QOqJ89DXvCc8\"\nneo4j_url = f\"neo4j+s://{neo4j_id}.databases.neo4j.io\"\n\nclass GraphRAG:\n    def __init__(self, chunk_df):\n        self.chunk_df = chunk_df\n        self.documents = chunk_df[\"content\"].to_list()\n        self.G = nx.Graph()\n        self.client = genai.GenerativeModel(\"gemini-2.0-flash\")\n\n    def get_triplets(self, text):\n        prompt = textwrap.dedent(\"\"\"\n        Extract entity relation triplets from the given text. Use exact text for extraction. Do not paraphrase or overlap entities.\n        Provide meaningful attributes to add context.\n        \"\"\")\n\n        examples = [\n            lx.data.ExampleData(\n                text=\"Social Security Board (Amendment) Act, No. 33 of 1999 amends the Social Security Board Act, No. 17 of 1996.\",\n                extractions=[\n                    lx.data.Extraction(\n                        extraction_class=\"law\",\n                        extraction_text=\"Social Security Board (Amendment) Act, No. 33 of 1999\",\n                    ),\n                    lx.data.Extraction(\n                        extraction_class=\"law\",\n                        extraction_text=\"Social Security Board Act, No. 17 of 1996\",\n                    ),\n                    lx.data.Extraction(\n                        extraction_class=\"relationship\",\n                        extraction_text=\"amends\",\n                        attributes={\"subject\": \"Social Security Board (Amendment) Act, No. 33 of 1999\",\n                                    \"object\": \"Social Security Board Act, No. 17 of 1996\"}\n                    ),\n                ]\n            )\n        ]\n\n        results = lx.extract(\n            text_or_documents=text,\n            prompt_description=prompt,\n            examples=examples,\n            model_id=\"gemini-2.0-flash\",\n            api_key=GEMINI_API_KEY,\n        )\n\n        print(results)\n\n        return results\n\n    \n    def build_kg(self):\n        triplets = {}\n        for text in self.documents:\n            annotated_doc = self.get_triplets(text)\n            for ex in annotated_doc.extractions:\n                triplets.append({\n                    \"subject\": ex.attributes[\"subject\"],\n                    \"object\": ex.attributes[\"object\"],\n                    \"relation\": ex.extraction_text\n                })\n\n        for triplet in triplets:\n            self.G.add_node(triplet[\"subject\"], type=\"entity\")\n            self.G.add_node(triplet[\"object\"], type=\"entity\")\n            self.G.add_edge(triplet[\"subject\"], triplet[\"object\"], relation=triplet[\"relation\"])\n\n        print(triplets)\n        return triplets\n\n    \n    def retrieve_subgraph(self, query):\n        query_entities = self.extract_entities(query)\n        results = []\n        for entity in query_entities.extractions:\n            entity_text = entity.extraction_text\n            result = [node for node in self.G.nodes if entity_text.lower() in node.lower()]\n            results.extend(result)\n\n        subgraph_nodes = set(results)\n        for r in subgraph_nodes:\n            subgraph_nodes.add(self.G.neighbors(r))\n            \n        return self.G.subgraph(subgraph_nodes)\n    \n\n    def extract_entities(self, text):\n        prompt = textwrap.dedent(\"\"\"\n        Extract entity relation triplets from the given text. Use exact text for extraction. Do not paraphrase or overlap entities.\n        Provide meaningful attributes to add context. Include attributes like entity type (law, organization, person, committee, etc.) \n        and relationship type (amends, renames, appoints, establishes, provides, collaborates_with, etc.).\n        \"\"\")\n\n        examples = [\n            lx.data.ExampleData(\n                text=\"Social Security Board (Amendment) Act, No. 33 of 1999 amends the Social Security Board Act, No. 17 of 1996.\",\n                extractions=[\n                    lx.data.Extraction(\n                        extraction_class=\"law\",\n                        extraction_text=\"Social Security Board (Amendment) Act, No. 33 of 1999\",\n                    ),\n                    lx.data.Extraction(\n                        extraction_class=\"law\",\n                        extraction_text=\"Social Security Board Act, No. 17 of 1996\",\n                    ),\n                ]\n            )\n        ]\n\n        results = lx.extract(\n            text_or_documents=text,\n            prompt_description=prompt,\n            examples=examples,\n            model_id=\"gemini-2.0-flash\",\n            api_key=GEMINI_API_KEY,\n        )\n\n        print(results.extractions)\n\n        return results\n\n\n    def serialize_subgraph(self, subgraph):\n        triples = []\n        for u, v, data in subgraph.edges(data=True):\n            relation = data.get(\"relation\", \"related_to\")\n            triples.append(f\"{u} → {relation} → {v}\")\n        print(triples)\n        return \"\\n\".join(triples)\n\n    \n    def generate_response(self, query) -> str:\n        subgraph = self.retrieve_subgraph(query)\n        kg_context = self.serialize_subgraph(subgraph)\n        print(kg_context)\n        prompt = f\"\"\"You are a legal assistant powered by a RAG system. Use the following knowledge graph context to answer the query accurately and concisely. If the context doesn't provide enough information, say so.\n\n            Context:\n            {kg_context}\n            \n            Query:\n            {query}\n            \n            Answer:\n            \"\"\"\n\n        response = self.client.generate_content(prompt)\n        return response.text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T07:10:26.901342Z","iopub.execute_input":"2025-09-07T07:10:26.901718Z","iopub.status.idle":"2025-09-07T07:10:26.948912Z","shell.execute_reply.started":"2025-09-07T07:10:26.901695Z","shell.execute_reply":"2025-09-07T07:10:26.948213Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"bills_para_chunks = chunk_df(bills, paragraph_chunk)\nrag = GraphRAG(bills_para_chunks)\n\nquery = \"What are the main objectives of the Jayanthipura association in community welfare and environment?\"\n\nrag.generate_response(query)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T17:05:04.767365Z","iopub.execute_input":"2025-09-07T17:05:04.767691Z","iopub.status.idle":"2025-09-07T17:05:04.772165Z","shell.execute_reply.started":"2025-09-07T17:05:04.767656Z","shell.execute_reply":"2025-09-07T17:05:04.771310Z"}},"outputs":[],"execution_count":3}]}